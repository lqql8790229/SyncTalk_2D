# SyncTalk_2D é¡¹ç›®åˆ†ææŠ¥å‘Š

## ä¸€ã€é¡¹ç›®èƒ½åŠ›æ¦‚è¿°

SyncTalk_2D æ˜¯ä¸€ä¸ª **2D å”‡å½¢åŒæ­¥è§†é¢‘ç”Ÿæˆç³»ç»Ÿ**ï¼Œæ ¸å¿ƒèƒ½åŠ›å¦‚ä¸‹ï¼š

| èƒ½åŠ› | æè¿° | å½“å‰çŠ¶æ€ |
|------|------|----------|
| éŸ³é¢‘ç‰¹å¾æå– | ä» WAV éŸ³é¢‘æå–è§†è§‰åŒæ­¥ç‰¹å¾ï¼ˆæ”¯æŒ AVE / HuBERT / WeNet ä¸‰ç§åç«¯ï¼‰ | âœ… å¯ç”¨ |
| äººè„¸æ£€æµ‹ | åŸºäº SCRFD (ONNX) æ£€æµ‹äººè„¸è¾¹ç•Œæ¡†å’Œå…³é”®ç‚¹ | âœ… å¯ç”¨ |
| é¢éƒ¨å…³é”®ç‚¹æ£€æµ‹ | åŸºäº PFLD-MobileOne æå– 110 ä¸ªå…³é”®ç‚¹ | âœ… å¯ç”¨ |
| SyncNet è®­ç»ƒ | å¯¹æ¯”å­¦ä¹ éŸ³è§†é¢‘åŒæ­¥åˆ¤åˆ«ç½‘ç»œ | âœ… å¯ç”¨ |
| UNet å”‡å½¢ç”Ÿæˆ | MobileNet-style U-Net + éŸ³é¢‘ç‰¹å¾èåˆï¼Œç”ŸæˆåŒæ­¥å”‡å½¢ | âœ… å¯ç”¨ |
| è§†é¢‘åˆæˆæ¨ç† | é€å¸§ç”Ÿæˆ â†’ åˆæˆå›åŸè§†é¢‘ â†’ ffmpeg æ··éŸ³è¾“å‡º | âœ… å¯ç”¨ |
| å¤šåˆ†è¾¨ç‡æ”¯æŒ | 160pxï¼ˆæ ‡å‡†ï¼‰å’Œ 328pxï¼ˆé«˜æ¸…ï¼‰ä¸¤ç§åˆ†è¾¨ç‡ | âœ… å¯ç”¨ |
| ONNX å¯¼å‡º | UNet æ¨¡å‹å¯å¯¼å‡ºä¸º ONNX æ ¼å¼ | âš ï¸ ä»£ç å­˜åœ¨ï¼Œæœªå®Œå–„ |

### å®Œæ•´æ•°æ®æµ

```
è¾“å…¥è§†é¢‘ (.mp4)
    â”‚
    â”œâ”€ ffmpeg â†’ 25fps è½¬æ¢ â†’ é€å¸§æå– JPG
    â”œâ”€ ffmpeg â†’ WAV 16kHz éŸ³é¢‘æå–
    â”‚
    â”œâ”€ SCRFD äººè„¸æ£€æµ‹ â†’ PFLD å…³é”®ç‚¹æ£€æµ‹ â†’ .lms å…³é”®ç‚¹æ–‡ä»¶
    â”œâ”€ AudioEncoder â†’ melé¢‘è°±å›¾ â†’ éŸ³é¢‘ç‰¹å¾ (.npy)
    â”‚
    â”œâ”€ [è®­ç»ƒ] SyncNet å¯¹æ¯”å­¦ä¹  â†’ syncnet checkpoint
    â”œâ”€ [è®­ç»ƒ] UNet (L1 + VGG19æ„ŸçŸ¥æŸå¤± + SyncNetæŸå¤±) â†’ unet checkpoint
    â”‚
    â””â”€ [æ¨ç†] éŸ³é¢‘ç‰¹å¾ + æ¨¡å‹æƒé‡ â†’ é€å¸§å”‡å½¢ç”Ÿæˆ â†’ åˆæˆ â†’ è¾“å‡ºè§†é¢‘
```

---

## äºŒã€é¡¹ç›®ç»“æ„åˆ†æ

### 2.1 æ–‡ä»¶ç»“æ„ï¼ˆå…± 21 ä¸ª Python æ–‡ä»¶ï¼Œ3714 è¡Œä»£ç ï¼‰

```
SyncTalk_2D/
â”œâ”€â”€ unet.py (318 è¡Œ)          # UNet æ¨¡å‹ - 160px ç‰ˆæœ¬
â”œâ”€â”€ unet_328.py (338 è¡Œ)      # UNet æ¨¡å‹ - 328px ç‰ˆæœ¬ï¼ˆå¤šä¸€å±‚ down/upï¼‰
â”œâ”€â”€ syncnet.py (263 è¡Œ)       # SyncNet åˆ¤åˆ«å™¨ + è®­ç»ƒ - 160px
â”œâ”€â”€ syncnet_328.py (268 è¡Œ)   # SyncNet åˆ¤åˆ«å™¨ + è®­ç»ƒ - 328px
â”œâ”€â”€ train.py (140 è¡Œ)         # ä¸»è®­ç»ƒè„šæœ¬ - 160px
â”œâ”€â”€ train_328.py (140 è¡Œ)     # ä¸»è®­ç»ƒè„šæœ¬ - 328px
â”œâ”€â”€ inference.py (133 è¡Œ)     # æ¨ç†è„šæœ¬ - 160px
â”œâ”€â”€ inference_328.py (159 è¡Œ) # æ¨ç†è„šæœ¬ - 328px
â”œâ”€â”€ datasetsss.py (147 è¡Œ)    # æ•°æ®é›†ç±» - 160px
â”œâ”€â”€ datasetsss_328.py (151 è¡Œ)# æ•°æ®é›†ç±» - 328px
â”œâ”€â”€ utils.py (158 è¡Œ)         # å·¥å…·å‡½æ•°ï¼ˆAudioEncoder, AudDataset, melé¢‘è°±ï¼‰
â”œâ”€â”€ training.sh               # è®­ç»ƒå¯åŠ¨è„šæœ¬ - 160px
â”œâ”€â”€ training_328.sh            # è®­ç»ƒå¯åŠ¨è„šæœ¬ - 328px
â”‚
â”œâ”€â”€ data_utils/
â”‚   â”œâ”€â”€ process.py (85 è¡Œ)         # æ•°æ®é¢„å¤„ç†å…¥å£
â”‚   â”œâ”€â”€ detect_face.py (106 è¡Œ)    # SCRFD äººè„¸æ£€æµ‹
â”‚   â”œâ”€â”€ get_landmark.py (113 è¡Œ)   # PFLD å…³é”®ç‚¹æ£€æµ‹
â”‚   â”œâ”€â”€ pfld_mobileone.py (336 è¡Œ) # PFLD æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ base_module.py (420 è¡Œ)    # MobileOne / Ghost æ¨¡å—
â”‚   â”œâ”€â”€ scrfd_2.5g_kps.onnx       # äººè„¸æ£€æµ‹ ONNX æ¨¡å‹
â”‚   â”œâ”€â”€ checkpoint_epoch_335.pth.tar # PFLD é¢„è®­ç»ƒæƒé‡
â”‚   â”œâ”€â”€ mean_face.txt              # å¹³å‡äººè„¸å…³é”®ç‚¹
â”‚   â””â”€â”€ ave/
â”‚       â”œâ”€â”€ audio.py (136 è¡Œ)      # éŸ³é¢‘å¤„ç†ï¼ˆmelé¢‘è°±ï¼‰
â”‚       â”œâ”€â”€ hparams.py (101 è¡Œ)    # è¶…å‚æ•°é…ç½®
â”‚       â”œâ”€â”€ test_w2l_audio.py (147 è¡Œ) # éŸ³é¢‘ç‰¹å¾æå–è„šæœ¬
â”‚       â””â”€â”€ models/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ audioEnc.py (54 è¡Œ)  # AudioEncoder æ¨¡å‹
â”‚
â”œâ”€â”€ model/checkpoints/
â”‚   â””â”€â”€ audio_visual_encoder.pth   # é¢„è®­ç»ƒ AudioEncoder (11MB)
â”‚
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ talk_hb.wav                # ç¤ºä¾‹éŸ³é¢‘
â”‚
â”œâ”€â”€ dataset/                       # è®­ç»ƒæ•°æ®ç›®å½•
â”œâ”€â”€ checkpoint/                    # UNet è®­ç»ƒè¾“å‡º
â”œâ”€â”€ syncnet_ckpt/                  # SyncNet è®­ç»ƒè¾“å‡º
â””â”€â”€ result/                        # æ¨ç†ç»“æœè¾“å‡º
```

### 2.2 æ¨¡å‹æ¶æ„è¯¦æƒ…

| æ¨¡å‹ | å‚æ•°é‡ | è¾“å…¥ | è¾“å‡º | ç”¨é€” |
|------|--------|------|------|------|
| AudioEncoder (utils.py) | 2,812,672 | mel [B,1,16,80] | [B,512] | éŸ³é¢‘â†’åµŒå…¥å‘é‡ |
| AudioEncoder (ave/) | åŒä¸Š | åŒä¸Š | åŒä¸Š | é¢„å¤„ç†é˜¶æ®µä½¿ç”¨ |
| UNet 160px | 12,163,591 | img [B,6,160,160] + audio [B,32,16,16] | [B,3,160,160] | å”‡å½¢ç”Ÿæˆ |
| UNet 328px | 12,186,935 | img [B,6,320,320] + audio [B,32,16,16] | [B,3,320,320] | é«˜æ¸…å”‡å½¢ç”Ÿæˆ |
| SyncNet | ~8M | face [B,3,H,W] + audio [B,C,H,W] | embeddings | éŸ³è§†é¢‘åŒæ­¥åˆ¤åˆ« |
| SCRFD | 2.5M (ONNX) | img [1,3,640,640] | bboxes, kps | äººè„¸æ£€æµ‹ |
| PFLD-MobileOne | ~1M | face [B,3,192,192] | [B,220] landmarks | å…³é”®ç‚¹æ£€æµ‹ |

### 2.3 160px vs 328px å·®å¼‚

| ç»´åº¦ | 160px | 328px |
|------|-------|-------|
| è£å‰ªå°ºå¯¸ | 168Ã—168 â†’ 160Ã—160 (4:164) | 328Ã—328 â†’ 320Ã—320 (4:324) |
| UNet æ·±åº¦ | 4 down + 4 up | 5 down + 5 up |
| UNet å‚æ•° | 12,163,591 | 12,186,935 (+23,344) |
| Mask åæ ‡ | (5,5,150,145) | (5,5,310,305) |
| **ä»£ç å·®å¼‚** | **ä»…~56è¡Œ** | **å¤šäº†ä¸€æ•´å¥—æ–‡ä»¶** |

> **å…³é”®å‘ç°**ï¼š10 ä¸ªæ–‡ä»¶ä¸­çš„ 5 å¯¹ä»…æœ‰æå¾®å°å·®å¼‚ï¼ˆæ€»å…± ~224 è¡Œ diffï¼‰ï¼Œä½†å¤åˆ¶äº† ~1500 è¡Œä»£ç ã€‚è¿™æ˜¯æœ€ä¸¥é‡çš„ä»£ç è´¨é‡é—®é¢˜ã€‚

---

## ä¸‰ã€é—®é¢˜è¯Šæ–­

### 3.1 ğŸ”´ ä¸¥é‡é—®é¢˜ï¼ˆå½±å“å•†ä¸šåŒ–å¯è¡Œæ€§ï¼‰

#### P0-1ï¼šå¤§é‡ä»£ç é‡å¤ï¼ˆ~40% ä»£ç æ˜¯å¤åˆ¶ç²˜è´´ï¼‰

5 å¯¹æ–‡ä»¶ï¼ˆunet, syncnet, train, inference, datasetsssï¼‰ä¹‹é—´ä»…æœ‰åˆ†è¾¨ç‡ç›¸å…³çš„å¾®å°å·®å¼‚ï¼Œå´å®Œå…¨å¤åˆ¶äº†æ•´ä¸ªæ–‡ä»¶ã€‚ä»»ä½• bug ä¿®å¤æˆ–åŠŸèƒ½æ”¹è¿›éƒ½éœ€è¦åœ¨ä¸¤ä¸ªæ–‡ä»¶ä¸­åŒæ—¶ä¿®æ”¹ï¼Œææ˜“é—æ¼ã€‚

```
æ–‡ä»¶å¯¹            å…±åŒè¡Œæ•°    å·®å¼‚è¡Œæ•°    é‡å¤ç‡
unet/unet_328       318        56        82%
syncnet/syncnet_328  263        33        87%
train/train_328      140        12        91%
inference/inf_328    133        71        47%
datasetsss/ds_328    147        52        65%
```

#### P0-2ï¼šæ—  API æ¥å£ï¼Œçº¯ CLI å·¥å…·

æ•´ä¸ªé¡¹ç›®åªæœ‰å‘½ä»¤è¡Œå…¥å£ï¼Œæ²¡æœ‰ä»»ä½• HTTP APIã€WebSocketã€gRPC ç­‰æ¥å£ã€‚å•†ä¸šäº§å“å¿…é¡»æä¾›æœåŠ¡åŒ–æ¥å£ã€‚

#### P0-3ï¼šç¡¬ç¼–ç  `.cuda()`ï¼Œæ— è®¾å¤‡æŠ½è±¡

è‡³å°‘ 8 å¤„ç›´æ¥è°ƒç”¨ `.cuda()`ï¼Œæ²¡æœ‰ç»Ÿä¸€çš„è®¾å¤‡ç®¡ç†ã€‚ä¼šå¯¼è‡´ï¼š
- æ— æ³•åœ¨ CPU ç¯å¢ƒè¿è¡Œå®Œæ•´æ¨ç†
- æ— æ³•æ”¯æŒå¤š GPU
- æ— æ³•åœ¨ Apple Silicon ä¸Šè¿è¡Œ

```python
# é—®é¢˜ç¤ºä¾‹ï¼ˆinference_328.py:68ï¼‰
net = Model(6, mode).cuda()  # ç¡¬ç¼–ç  CUDAï¼ŒCPU ç›´æ¥å´©æºƒ

# ä½†åŒæ–‡ä»¶ç¬¬37è¡Œå´æ­£ç¡®å¤„ç†äº†ï¼š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

#### P0-4ï¼šæ— é”™è¯¯å¤„ç†å’Œè¾“å…¥éªŒè¯

- `os.system()` è°ƒç”¨ä¸æ£€æŸ¥è¿”å›ç ï¼ˆffmpeg å¯èƒ½å¤±è´¥ä½†ä»£ç ç»§ç»­æ‰§è¡Œï¼‰
- æ— è¾“å…¥è§†é¢‘æ ¼å¼/åˆ†è¾¨ç‡éªŒè¯
- æ–‡ä»¶ I/O æ—  try/catch
- é¢éƒ¨æœªæ£€æµ‹åˆ°æ—¶ç›´æ¥å´©æºƒï¼ˆ`cropped_imgs[0]` å¯èƒ½ IndexErrorï¼‰

#### P0-5ï¼šè®­ç»ƒç¼ºå°‘å…³é”® bug â€”â€” `optimizer.zero_grad()` é—æ¼

```python
# syncnet.py:249-251 - ä¸¥é‡ bug
loss.backward()
optimizer.step()  # â† ç¼ºå°‘ optimizer.zero_grad()ï¼æ¢¯åº¦ä¼šç´¯ç§¯
```

### 3.2 ğŸŸ¡ ä¸­ç­‰é—®é¢˜ï¼ˆå½±å“äº§å“è´¨é‡å’Œå¼€å‘æ•ˆç‡ï¼‰

#### P1-1ï¼šæ— é…ç½®ç®¡ç†ç³»ç»Ÿ

è¶…å‚æ•°åˆ†æ•£åœ¨ä»£ç å„å¤„ï¼Œç¼ºå°‘ç»Ÿä¸€çš„é…ç½®æ–‡ä»¶ï¼š
- è£å‰ªåæ ‡ç¡¬ç¼–ç ï¼š`4:324`, `(5,5,310,305)`
- å…³é”®ç‚¹ç´¢å¼•ç¡¬ç¼–ç ï¼š`lms[1][0]`, `lms[52][1]`, `lms[31][0]`
- éŸ³é¢‘ç‰¹å¾ reshape ç»´åº¦ç¡¬ç¼–ç ï¼š`32,16,16` / `32,32,32` / `256,16,32`
- è®­ç»ƒå‚æ•°æ•£è½å„å¤„ï¼š`batch_size=16`, `num_workers=32`, `lr=0.001`
- æŸå¤±æƒé‡ç¡¬ç¼–ç ï¼š`loss_pixel + loss_PerceptualLoss*0.01 + 10*sync_loss`

#### P1-2ï¼šæ— ä¾èµ–ç®¡ç†

æ²¡æœ‰ `requirements.txt`ã€`setup.py`ã€`pyproject.toml`ã€‚ä¾èµ–ä»…åœ¨ README ä¸­åˆ—å‡ºï¼Œç‰ˆæœ¬ç®¡ç†å®Œå…¨ç¼ºå¤±ã€‚

#### P1-3ï¼šç›¸å¯¹å¯¼å…¥é—®é¢˜

`data_utils/ave/` å’Œ `data_utils/` ä¸‹çš„æ¨¡å—ä½¿ç”¨éšå¼ç›¸å¯¹å¯¼å…¥ï¼ˆ`from hparams import ...`ã€`from base_module import ...`ï¼‰ï¼Œå¿…é¡»ä»ç‰¹å®šç›®å½•è¿è¡Œï¼Œæ— æ³•ä½œä¸ºæ ‡å‡† Python åŒ…å¯¼å…¥ã€‚

#### P1-4ï¼šè®­ç»ƒç®¡çº¿ä¸å®Œæ•´

| ç¼ºå¤±é¡¹ | å½±å“ |
|--------|------|
| æ— å­¦ä¹ ç‡è°ƒåº¦å™¨ | è®­ç»ƒä¸ç¨³å®šï¼Œæ”¶æ•›æ…¢ |
| æ— éªŒè¯é›† | æ— æ³•æ£€æµ‹è¿‡æ‹Ÿåˆ |
| æ—  early stopping | æµªè´¹è®­ç»ƒèµ„æº |
| æ— æ··åˆç²¾åº¦è®­ç»ƒ (AMP) | è®­ç»ƒé€Ÿåº¦æ…¢ï¼Œæ˜¾å­˜æµªè´¹ |
| æ— åˆ†å¸ƒå¼è®­ç»ƒ | æ— æ³•æ‰©å±•åˆ°å¤š GPU |
| æ— æ–­ç‚¹ç»­è®­ | è®­ç»ƒä¸­æ–­éœ€ä»å¤´å¼€å§‹ |
| æ—  TensorBoard/WandB | æ— æ³•ç›‘æ§è®­ç»ƒè¿‡ç¨‹ |
| æ— æ•°æ®å¢å¼º | æ³›åŒ–èƒ½åŠ›å·® |

#### P1-5ï¼šæ¨ç†æ€§èƒ½ä½

- **é€å¸§å¤„ç†**ï¼šæ²¡æœ‰æ‰¹é‡æ¨ç†ï¼Œæ¯å¸§ç‹¬ç«‹å‰å‘ä¼ æ’­
- **MJPG ä¸­é—´ç¼–ç **ï¼šä¸´æ—¶è§†é¢‘ä½¿ç”¨æœ‰æŸ MJPG ç¼–ç ï¼Œå¼•å…¥è´¨é‡æŸå¤±
- **æ— æµå¼å¤„ç†**ï¼šå¿…é¡»å…ˆå¤„ç†å®Œæ•´ä¸ªéŸ³é¢‘ï¼Œå†é€å¸§ç”Ÿæˆ
- **Shell å‘½ä»¤æ“ä½œæ–‡ä»¶**ï¼š`os.system(f"rm ...")` ä»£æ›¿ `os.remove()`

### 3.3 ğŸŸ¢ ä½ä¼˜å…ˆçº§é—®é¢˜ï¼ˆä»£ç è´¨é‡ï¼‰

| é—®é¢˜ | ä½ç½® | æè¿° |
|------|------|------|
| åºŸå¼ƒ API | `unet.py:249,268` | `F.sigmoid()` åº”æ”¹ä¸º `torch.sigmoid()` |
| åºŸå¼ƒ API | `train.py:38` | `vgg19(pretrained=True)` åº”ä½¿ç”¨ `weights=` |
| æ­»ä»£ç  | `syncnet*.py` | `nonorm_Conv2d`ã€`Conv2dTranspose` æœªä½¿ç”¨ |
| æ­»ä»£ç  | `datasetsss*.py:61-73` | `get_audio_features_1()` æœªä½¿ç”¨ |
| æ­»ä»£ç  | `pfld_mobileone.py:136` | `PFLD_GhostOne_WithSTN` super() è°ƒç”¨é”™è¯¯ |
| æœªä½¿ç”¨å¯¼å…¥ | `get_landmark.py:2` | `from os import wait3` |
| è°ƒè¯•è¾“å‡º | å¤šå¤„ | é—ç•™çš„ `print(x1.shape)` ç­‰è°ƒè¯•è¯­å¥ |
| å‘½åé—®é¢˜ | `datasetsss.py` | æ–‡ä»¶å triple 's' |
| å‘½åå†²çª | `syncnet.py:14` | ç±»å `Dataset` ä¸ PyTorch å†…ç½®ç±»å†²çª |
| æ³¨é‡Šä»£ç  | å…¨å±€ | å¤§é‡è¢«æ³¨é‡Šçš„ä»£ç å—ï¼Œé™ä½å¯è¯»æ€§ |

---

## å››ã€å•†ä¸šåŒ–æ”¹é€ æ–¹æ¡ˆ

### 4.1 ç¬¬ä¸€é˜¶æ®µï¼šä»£ç é‡æ„ï¼ˆ2-3 å‘¨ï¼‰

**ç›®æ ‡**ï¼šæ¶ˆé™¤æŠ€æœ¯å€ºåŠ¡ï¼Œå»ºç«‹å¯ç»´æŠ¤çš„ä»£ç åŸºç¡€ã€‚

#### 4.1.1 ç»Ÿä¸€åˆ†è¾¨ç‡å˜ä½“

å°† 5 å¯¹é‡å¤æ–‡ä»¶åˆå¹¶ä¸ºå•ä¸€å¯é…ç½®ç‰ˆæœ¬ï¼š

```python
# æ”¹é€ å‰ï¼š10 ä¸ªæ–‡ä»¶
unet.py / unet_328.py
syncnet.py / syncnet_328.py
train.py / train_328.py
inference.py / inference_328.py
datasetsss.py / datasetsss_328.py

# æ”¹é€ åï¼š5 ä¸ªæ–‡ä»¶ + é…ç½®
models/unet.py          # é€šè¿‡ config.resolution æ§åˆ¶å±‚æ•°
models/syncnet.py        # ç»Ÿä¸€çš„ SyncNet
training/trainer.py      # ç»Ÿä¸€è®­ç»ƒé€»è¾‘
inference/engine.py      # ç»Ÿä¸€æ¨ç†å¼•æ“
data/dataset.py          # ç»Ÿä¸€æ•°æ®é›†ç±»
configs/160.yaml         # 160px é…ç½®
configs/328.yaml         # 328px é…ç½®
configs/512.yaml         # æœªæ¥ 512px é…ç½®
```

#### 4.1.2 Python åŒ…åŒ–

```
synctalk/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # åŸºç¡€é…ç½® dataclass
â”‚   â”œâ”€â”€ presets/
â”‚   â”‚   â”œâ”€â”€ 160.yaml
â”‚   â”‚   â”œâ”€â”€ 328.yaml
â”‚   â”‚   â””â”€â”€ 512.yaml
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unet.py              # ç»Ÿä¸€ UNetï¼ˆå‚æ•°åŒ–å±‚æ•°ï¼‰
â”‚   â”œâ”€â”€ syncnet.py            # ç»Ÿä¸€ SyncNet
â”‚   â”œâ”€â”€ audio_encoder.py      # ç»Ÿä¸€ AudioEncoder
â”‚   â””â”€â”€ blocks.py             # å…¬å…±æ¨¡å—ï¼ˆInvertedResidual ç­‰ï¼‰
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py            # ç»Ÿä¸€æ•°æ®é›†
â”‚   â”œâ”€â”€ preprocessing.py      # æ•°æ®é¢„å¤„ç†
â”‚   â”œâ”€â”€ face_detection.py     # äººè„¸æ£€æµ‹å°è£…
â”‚   â”œâ”€â”€ landmark.py           # å…³é”®ç‚¹æ£€æµ‹å°è£…
â”‚   â””â”€â”€ audio.py              # éŸ³é¢‘å¤„ç†
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py            # è®­ç»ƒå™¨ï¼ˆæ”¯æŒ AMPã€DDPã€æ–­ç‚¹ç»­è®­ï¼‰
â”‚   â”œâ”€â”€ losses.py             # æŸå¤±å‡½æ•°ï¼ˆL1ã€Perceptualã€Syncï¼‰
â”‚   â””â”€â”€ scheduler.py          # å­¦ä¹ ç‡è°ƒåº¦
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ engine.py             # æ¨ç†å¼•æ“
â”‚   â””â”€â”€ video_composer.py     # è§†é¢‘åˆæˆ
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                # FastAPI åº”ç”¨
â”‚   â”œâ”€â”€ routes.py             # API è·¯ç”±
â”‚   â””â”€â”€ schemas.py            # è¯·æ±‚/å“åº”æ¨¡å‹
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ device.py             # ç»Ÿä¸€è®¾å¤‡ç®¡ç†
â”‚   â”œâ”€â”€ io.py                 # æ–‡ä»¶ I/O å·¥å…·
â”‚   â””â”€â”€ logging.py            # ç»“æ„åŒ–æ—¥å¿—
â”œâ”€â”€ cli.py                    # CLI å…¥å£
â””â”€â”€ pyproject.toml            # ä¾èµ–ç®¡ç†
```

#### 4.1.3 ç»Ÿä¸€è®¾å¤‡ç®¡ç†

```python
# synctalk/utils/device.py
import torch

def get_device(device_str: str = "auto") -> torch.device:
    if device_str == "auto":
        if torch.cuda.is_available():
            return torch.device("cuda")
        elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            return torch.device("mps")
        return torch.device("cpu")
    return torch.device(device_str)
```

#### 4.1.4 é…ç½®ç³»ç»Ÿ

```python
# synctalk/configs/base.py
from dataclasses import dataclass, field

@dataclass
class ModelConfig:
    resolution: int = 328
    n_channels: int = 6
    channel_multipliers: list = field(default_factory=lambda: [32, 64, 128, 256, 512])
    asr_mode: str = "ave"  # "ave" | "hubert" | "wenet"
    n_down_layers: int = 5  # è‡ªåŠ¨æ ¹æ®åˆ†è¾¨ç‡è®¡ç®—

@dataclass
class TrainConfig:
    epochs: int = 100
    batch_size: int = 8
    lr: float = 1e-3
    num_workers: int = 8
    use_syncnet: bool = True
    loss_weights: dict = field(default_factory=lambda: {
        "pixel": 1.0, "perceptual": 0.01, "sync": 10.0
    })
    use_amp: bool = True
    save_interval: int = 5

@dataclass
class InferenceConfig:
    batch_size: int = 4  # æ‰¹é‡å¸§å¤„ç†
    device: str = "auto"
    output_codec: str = "libx264"
    output_crf: int = 20
```

### 4.2 ç¬¬äºŒé˜¶æ®µï¼šæ¨¡å‹å’Œè®­ç»ƒæ”¹è¿›ï¼ˆ3-4 å‘¨ï¼‰

#### 4.2.1 è®­ç»ƒç®¡çº¿å‡çº§

| æ”¹è¿›é¡¹ | æ–¹æ¡ˆ | é¢„æœŸæ”¶ç›Š |
|--------|------|----------|
| æ··åˆç²¾åº¦è®­ç»ƒ | `torch.cuda.amp.autocast()` | è®­ç»ƒé€Ÿåº¦ Ã—1.5-2ï¼Œæ˜¾å­˜å‡åŠ |
| åˆ†å¸ƒå¼è®­ç»ƒ | PyTorch DDP | å¤š GPU çº¿æ€§åŠ é€Ÿ |
| å­¦ä¹ ç‡è°ƒåº¦ | CosineAnnealingLR + Warmup | æ›´å¥½çš„æ”¶æ•› |
| æ•°æ®å¢å¼º | é¢œè‰²æŠ–åŠ¨ã€æ°´å¹³ç¿»è½¬ã€éšæœºè£å‰ª | æ³›åŒ–èƒ½åŠ›æå‡ |
| éªŒè¯é›†è¯„ä¼° | PSNR / SSIM / LMD / SyncNet Score | é‡åŒ–æ¨¡å‹è´¨é‡ |
| æ–­ç‚¹ç»­è®­ | ä¿å­˜å®Œæ•´è®­ç»ƒçŠ¶æ€ | è®­ç»ƒä¸­æ–­æ¢å¤ |
| è®­ç»ƒç›‘æ§ | TensorBoard / WandB | å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ |

#### 4.2.2 æ¨¡å‹æ¶æ„å‡çº§

- **æ„ŸçŸ¥æŸå¤±**ï¼šVGG19 â†’ LPIPSï¼ˆæ›´è½»é‡ï¼Œæ•ˆæœæ›´å¥½ï¼‰
- **GAN åˆ¤åˆ«å™¨**ï¼šæ·»åŠ  PatchGAN åˆ¤åˆ«å™¨ï¼Œæå‡ç”Ÿæˆè´¨é‡
- **æ³¨æ„åŠ›æœºåˆ¶**ï¼šåœ¨èåˆå±‚æ·»åŠ  Cross-Attentionï¼ˆéŸ³é¢‘â†’è§†è§‰ï¼‰
- **æ›´é«˜åˆ†è¾¨ç‡**ï¼šæ”¯æŒ 512px / 1024px
- **æ¨¡å‹å‹ç¼©**ï¼šçŸ¥è¯†è’¸é¦ + é‡åŒ–ï¼ˆINT8/FP16ï¼‰â†’ å®æ—¶æ¨ç†

#### 4.2.3 æ¨ç†ä¼˜åŒ–

```python
# æ‰¹é‡æ¨ç†ï¼ˆå½“å‰é€å¸§ â†’ æ”¹ä¸ºæ‰¹é‡ï¼‰
# é¢„æœŸåŠ é€Ÿ 3-5Ã—
for batch in chunks(audio_feats, batch_size=8):
    with torch.no_grad(), torch.cuda.amp.autocast():
        preds = net(batch_imgs, batch_audio)

# TensorRT éƒ¨ç½²ï¼ˆæ¨ç†é€Ÿåº¦ Ã—2-5ï¼‰
import torch_tensorrt
trt_model = torch_tensorrt.compile(model, inputs=[img_spec, audio_spec])
```

### 4.3 ç¬¬ä¸‰é˜¶æ®µï¼šæœåŠ¡åŒ–ï¼ˆ3-4 å‘¨ï¼‰

#### 4.3.1 REST API (FastAPI)

```python
# API è®¾è®¡
POST /api/v1/projects              # åˆ›å»ºé¡¹ç›®ï¼ˆä¸Šä¼ è®­ç»ƒè§†é¢‘ï¼‰
GET  /api/v1/projects/{id}         # æŸ¥è¯¢é¡¹ç›®çŠ¶æ€
POST /api/v1/projects/{id}/train   # å¯åŠ¨è®­ç»ƒ
GET  /api/v1/projects/{id}/train/status  # è®­ç»ƒè¿›åº¦

POST /api/v1/inference             # æäº¤æ¨ç†ä»»åŠ¡
GET  /api/v1/inference/{id}        # æŸ¥è¯¢æ¨ç†ç»“æœ
GET  /api/v1/inference/{id}/video  # ä¸‹è½½ç”Ÿæˆè§†é¢‘

POST /api/v1/realtime/start        # WebSocket å®æ—¶æ¨ç†
```

#### 4.3.2 å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—

```
ç”¨æˆ·è¯·æ±‚ â†’ FastAPI â†’ Celery/RQ â†’ GPU Worker â†’ ç»“æœå›è°ƒ
                                       â†“
                                 Redis (ä»»åŠ¡çŠ¶æ€)
                                       â†“
                                 S3/MinIO (è§†é¢‘å­˜å‚¨)
```

#### 4.3.3 å®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# å¤šé˜¶æ®µæ„å»º
FROM pytorch/pytorch:2.2.0-cuda12.1 AS base
# åº”ç”¨å±‚
FROM base AS app
COPY synctalk/ /app/synctalk/
CMD ["uvicorn", "synctalk.api.app:app", "--host", "0.0.0.0"]
```

```yaml
# docker-compose.yml
services:
  api:
    build: .
    ports: ["8000:8000"]
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
  worker:
    build: .
    command: celery -A synctalk.tasks worker --concurrency=1
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
  redis:
    image: redis:7
  minio:
    image: minio/minio
```

### 4.4 ç¬¬å››é˜¶æ®µï¼šå•†ä¸šåŠŸèƒ½ï¼ˆ4-6 å‘¨ï¼‰

| åŠŸèƒ½ | æè¿° | ä¼˜å…ˆçº§ |
|------|------|--------|
| ç”¨æˆ·ç³»ç»Ÿ | æ³¨å†Œã€ç™»å½•ã€API Key ç®¡ç† | P0 |
| ç”¨é‡è®¡è´¹ | æŒ‰æ¨ç†æ—¶é•¿è®¡è´¹ã€é…é¢ç®¡ç† | P0 |
| æ¨¡å‹ç®¡ç† | ç‰ˆæœ¬æ§åˆ¶ã€A/B æµ‹è¯• | P1 |
| å¤šç§Ÿæˆ· | æ•°æ®éš”ç¦»ã€èµ„æºéš”ç¦» | P1 |
| ç›‘æ§å‘Šè­¦ | Prometheus + Grafanaã€GPU åˆ©ç”¨ç‡ | P1 |
| SDK | Python SDKã€JS SDK | P2 |
| ç®¡ç†åå° | ç”¨æˆ·ç®¡ç†ã€ä»»åŠ¡ç›‘æ§ã€ç³»ç»Ÿé…ç½® | P2 |
| å®æ—¶æ¨æµ | WebRTC / RTMP å®æ—¶æ•°å­—äºº | P2 |
| ç§»åŠ¨ç«¯ | ONNX Runtime Mobile / CoreML | P3 |

---

## äº”ã€æ”¹é€ è·¯çº¿å›¾æ€»ç»“

```
ç¬¬ä¸€é˜¶æ®µ (2-3å‘¨)ï¼šä»£ç é‡æ„
  â”œâ”€ åˆå¹¶ 160/328 é‡å¤ä»£ç 
  â”œâ”€ Python åŒ…åŒ– + pyproject.toml
  â”œâ”€ ç»Ÿä¸€è®¾å¤‡ç®¡ç† + é…ç½®ç³»ç»Ÿ
  â”œâ”€ ä¿®å¤å·²çŸ¥ bugï¼ˆzero_gradã€é”™è¯¯å¤„ç†ï¼‰
  â””â”€ æ·»åŠ å•å…ƒæµ‹è¯•

ç¬¬äºŒé˜¶æ®µ (3-4å‘¨)ï¼šæ¨¡å‹å’Œè®­ç»ƒ
  â”œâ”€ AMP + DDP + LR Scheduler
  â”œâ”€ æ•°æ®å¢å¼º + éªŒè¯é›†
  â”œâ”€ æ¨ç†æ‰¹é‡åŒ– + TensorRT
  â””â”€ æ›´é«˜åˆ†è¾¨ç‡æ”¯æŒ

ç¬¬ä¸‰é˜¶æ®µ (3-4å‘¨)ï¼šæœåŠ¡åŒ–
  â”œâ”€ FastAPI REST API
  â”œâ”€ Celery å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—
  â”œâ”€ Docker + K8s éƒ¨ç½²
  â””â”€ å¯¹è±¡å­˜å‚¨é›†æˆ

ç¬¬å››é˜¶æ®µ (4-6å‘¨)ï¼šå•†ä¸šåŠŸèƒ½
  â”œâ”€ ç”¨æˆ·ç³»ç»Ÿ + è®¡è´¹
  â”œâ”€ ç›‘æ§ + æ—¥å¿—
  â”œâ”€ SDK + æ–‡æ¡£
  â””â”€ å®æ—¶æ¨æµ
```

**é¢„è®¡æ€»å·¥æ—¶**ï¼š12-17 å‘¨ï¼ˆä¸€ä¸ª 2-3 äººå›¢é˜Ÿï¼‰

---

## å…­ã€å¿«é€Ÿèƒœåˆ©ï¼ˆQuick Winsï¼‰

ä»¥ä¸‹æ”¹åŠ¨å¯ä»¥åœ¨ 1-2 å¤©å†…å®Œæˆï¼Œç«‹å³æå‡ä»£ç è´¨é‡ï¼š

1. **ä¿®å¤ `optimizer.zero_grad()` é—æ¼** â€” syncnet.py:249
2. **æ›¿æ¢æ‰€æœ‰ `.cuda()` ä¸º `to(device)`** â€” ç»Ÿä¸€è®¾å¤‡ç®¡ç†
3. **åˆ›å»º `requirements.txt`** â€” é”å®šä¾èµ–ç‰ˆæœ¬
4. **æ›¿æ¢ `os.system()` ä¸º `subprocess.run()`** â€” é”™è¯¯æ£€æŸ¥
5. **åˆ é™¤æ­»ä»£ç å’Œè°ƒè¯•è¾“å‡º** â€” æå‡å¯è¯»æ€§
6. **æ·»åŠ  `.gitignore`** â€” æ’é™¤ `__pycache__`ã€`.venv`ã€`dataset/`
7. **æ·»åŠ è¾“å…¥éªŒè¯** â€” æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€æ ¼å¼æ˜¯å¦æ­£ç¡®
